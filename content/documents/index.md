# Documents

This page holds relevant documents. There's a CV, posters, conference abstracts and any other documents to be posted publicly.

---

## CV

[Curriculum Vitae 2025](cv_2025_english.pdf): Overview of work experience, projects, education, and skills. This document may be outdated. If you want the most recent version feel free to send me an email.

---

## Posters \& Abstracts

[Defining OoD detection for BCIs abstract](defining_ood_abstract.pdf) and [corresponding poster](poster_defining_ood.pdf), presented at the BCI Society Meeting 2025. We introduce the detection of "unusual" samples as an underexplored and challening problem in Brain-Computer Interfaces. 

[Optimizing P300 Speller Performance through UQ abstract](bci_uq_abstract.pdf) and [corresponding poster](bci_uq_poster.pdf), presented at the BCI Society Meeting 2025 by Bernard Renardi. We demonstrate how we can use uncertainty estimation to accept a P300-spelled letter using fewer stimuli when sufficient evidence is accumulated. We also show that in some instances even after the maximum number of trials there's still too much uncertainty to accept a prediction.

[Uncertainty Quantification for Motor Imagery BCI - Machine Learning vs. Deep Learning poster](uqbci_dl_vs_ml.pdf), and a [corresponding youtube video](https://youtu.be/LddnmJ4SgE0), presented at Decoding the Brain Time Series session at IEEE Machine Learning for Signal Processing, with Joris Suurmeijer. We demonstrated that classical ML methods for BCI have better uncertainty estimation than Deep Learning methods. We show that MDRM (Minimum Distance to Riemannian Mean) does not have well-calibrated uncertainties, and propose a solution to this.

[How Disentangled are your classification uncertainties?](disentanglement_gl_it_poster.pdf), presented at the Uncertainty Quantification for High Dimensional Problems workshop at CWI (not peer-reviewed). We explored two formulations of estimating data and model uncertainty in Machine Learning and investigate whether these uncertainties are intertwined over multiple BNNs, models and tasks. We show that neither guarantees disentanglement, but that Information Theoretic disentangling is overall preferable. 

[Verbalized Uncertainty Estimation Robustness on Corrupted Images in Vision-Language Models poster]([poster_vlm_uncertainty.pdf]), presented at TrustNLP workshop at NAACL, by Mirko Borszukovszk. We explored the ability of large Vision-Language Models to indicate their uncertainty as part of their answer under damaged images. We found that these systems are consistently overconfident, especially in regression/counting tasks. The best models were the ones that would sometimes refuse to answer. This led to better calibrated uncertainties. 

---

## Other Documents

[Academic Writing advice for Machine Learning](ML_writing_guide.pdf). I find myself giving the same writing advice to thesis students. In part this is because what is considered good writing is different per field. This document outlines some advice for writing Machine Learning theses and papers. It complies with common expecations in Machine Learning literature, but is of course also influenced by my own preferences. 

